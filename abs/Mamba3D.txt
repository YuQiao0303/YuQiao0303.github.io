Existing Transformer-based models for point cloud analysis suffer from quadratic complexity, leading to compromised point cloud resolution and information loss. We present Mamba3D, a state space model tailored for point cloud learning, with a Local Norm Pooling (LNP) block for local feature extraction and a bidirectional SSM (bi-SSM) for better global features. Mamba3D surpasses Transformer-based counterparts and concurrent works in multiple tasks, achieving multiple SoTA, with linear complexity.